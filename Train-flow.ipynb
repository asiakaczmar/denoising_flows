{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "agreed-arctic",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# from flows.context_flow import ContextFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "sonic-franklin",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CsvDataset(Dataset):\n",
    "\n",
    "    def __init__(self, z_csv_file, y_csv_file):\n",
    "        self.df_z = pd.read_csv(z_csv_file)\n",
    "        self.df_y = pd.read_csv(y_csv_file)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df_z)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        z = torch.tensor(self.df_z.iloc[idx, :].values, dtype=torch.float)\n",
    "        y = torch.tensor(self.df_y.iloc[idx, :].values, dtype=torch.float)\n",
    "        return z, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "agricultural-hospital",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from nflows.flows.base import Flow\n",
    "from nflows.distributions.normal import ConditionalDiagonalNormal\n",
    "from nflows.transforms.base import CompositeTransform\n",
    "from nflows.transforms.autoregressive import MaskedAffineAutoregressiveTransform\n",
    "from nflows.transforms.permutations import ReversePermutation\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from tqdm import trange\n",
    "\n",
    "from utils_flow.context import generate_one_hot_context\n",
    "from utils_flow.early_stopping.EarlyStopping import EarlyStopping\n",
    "\n",
    "\n",
    "class ContextFlow(BaseEstimator, ClassifierMixin):\n",
    "\n",
    "    def __init__(self, z_dim=20, context_dim=10, num_layers=5, num_iter=1000, patience=10, device='cpu'):\n",
    "        \"\"\"\n",
    "        Context Flow model wrapper.\n",
    "        Parameters\n",
    "        ----------\n",
    "        z_dim : Number of dimensions in the latent space\n",
    "        context_dim : Number of classes to model\n",
    "        num_layers : Number of Flow layers\n",
    "        num_iter : Number of iterations during training\n",
    "        \"\"\"\n",
    "        self.z_dim = z_dim\n",
    "        self.context_dim = context_dim\n",
    "        self.num_layers = num_layers\n",
    "        self.num_classes = context_dim\n",
    "        self.num_iter = num_iter\n",
    "        self.patience = patience\n",
    "        self.device = device\n",
    "\n",
    "    def fit(self, dl):\n",
    "        self.model = get_context_flow(inputs_dim=self.z_dim, context_dim=self.context_dim, num_layers=self.num_layers)\n",
    "        self.model.to(self.device)\n",
    "        optimizer = optim.Adam(self.model.parameters())\n",
    "        es = EarlyStopping(patience=self.patience)\n",
    "\n",
    "        with trange(self.num_iter) as t:\n",
    "            for _ in t:\n",
    "                for x, y in dl:\n",
    "                    x, y = x.to(self.device), y.to(self.device)\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = -self.model.log_prob(inputs=x, context=y).mean()\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                    t.set_postfix(loss=loss.item())\n",
    "\n",
    "                if es.step(loss):\n",
    "                    break\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict_proba(self, x):\n",
    "        if type(x) is not torch.Tensor:\n",
    "            x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "        results = []\n",
    "\n",
    "        for i in range(self.num_classes):\n",
    "            context = generate_one_hot_context(np.array(len(x) * [i]), num_classes=self.num_classes)\n",
    "            results.append(self.model.log_prob(x, context).detach().numpy())\n",
    "\n",
    "        y_prob = np.stack(results, axis=1)\n",
    "        y_prob = y_prob / y_prob.sum(axis=1, keepdims=True)\n",
    "        return y_prob\n",
    "\n",
    "    def predict(self, x):\n",
    "        if type(x) is not torch.Tensor:\n",
    "            x = torch.tensor(x, dtype=torch.float)\n",
    "\n",
    "        y = self.predict_proba(x).argmax(axis=1)\n",
    "        return y\n",
    "\n",
    "\n",
    "def get_context_flow(inputs_dim, context_dim, num_layers):\n",
    "    base_dist = ConditionalDiagonalNormal(\n",
    "        shape=[inputs_dim], \n",
    "        context_encoder=nn.Linear(context_dim, 2 * inputs_dim)\n",
    "    )\n",
    "\n",
    "    transforms = []\n",
    "    for _ in range(num_layers):\n",
    "        transforms.append(ReversePermutation(features=inputs_dim))\n",
    "        transforms.append(MaskedAffineAutoregressiveTransform(\n",
    "            features=inputs_dim, hidden_features=2 * inputs_dim, context_features=context_dim)\n",
    "        )\n",
    "    transform = CompositeTransform(transforms)\n",
    "\n",
    "    flow = Flow(transform, base_dist)\n",
    "    return flow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aggregate-graham",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_train = CsvDataset('data/z_train.csv', 'data/y_train_gender.csv')\n",
    "dl_train = DataLoader(dataset_train, batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "arabic-neighbor",
   "metadata": {},
   "outputs": [],
   "source": [
    "flow = ContextFlow(z_dim = 128, context_dim = 1, num_layers = 5, num_iter = 2, device = 'cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "reverse-locking",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:07<00:00, 33.98s/it, loss=182]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ContextFlow(context_dim=1, device='cuda:0', num_iter=2, z_dim=128)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flow.fit(dl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "analyzed-halifax",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(flow.model, 'flow-gender.pkt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
