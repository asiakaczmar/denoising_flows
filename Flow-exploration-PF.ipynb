{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'models.flow'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-218dad8bb2dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mPointFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_parser\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPointFlow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnetworks\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mPointFlow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/src/PointFlow/models/networks.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_point_cnf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mget_latent_cnf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtruncated_normal\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce_tensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstandard_normal_logprob\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'models.flow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import joblib\n",
    "import numpy as np\n",
    "import open3d as o3d\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from PointFlow.args import get_parser\n",
    "from PointFlow.models.networks import PointFlow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "parser = get_parser()\n",
    "args = parser.parse_args(\"--cates all --resume_checkpoint logs/shapenet/PointFlow/all/checkpoints/model.pt --dims 512-512-512 --use_deterministic_encoder --evaluate_recon --resume_dataset_mean logs/shapenet/PointFlow/all/checkpoints/train_set_mean.npy --resume_dataset_std logs/shapenet/PointFlow/all/checkpoints/train_set_std.npy\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(args):\n",
    "    model = PointFlow(args)\n",
    "\n",
    "    def _transform_(m):\n",
    "        return nn.DataParallel(m)\n",
    "\n",
    "    model.multi_gpu_wrapper(_transform_)\n",
    "\n",
    "    print(\"Resume Path:%s\" % args.resume_checkpoint)\n",
    "    checkpoint = torch.load(args.resume_checkpoint, map_location='cpu')\n",
    "    model.load_state_dict(checkpoint)\n",
    "    _ = model.eval()\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_flow(args):\n",
    "    save_dir = os.path.dirname(args.resume_checkpoint)\n",
    "    flow = torch.load(os.path.join(save_dir, 'flow.pkt'))\n",
    "    return flow\n",
    "\n",
    "\n",
    "def load_label_encoder(args):\n",
    "    save_dir = os.path.dirname(args.resume_checkpoint)\n",
    "    le = joblib.load(os.path.join(save_dir, 'label_encoder.joblib'))\n",
    "    return le\n",
    "\n",
    "\n",
    "def load_data(args):\n",
    "    save_dir = os.path.dirname(args.resume_checkpoint)\n",
    "    path_df_train = os.path.join(save_dir, 'train_latent_space.csv')\n",
    "    path_df_test = os.path.join(save_dir, 'test_latent_space.csv')\n",
    "\n",
    "    df_train = pd.read_csv(path_df_train)\n",
    "    df_test = pd.read_csv(path_df_test)\n",
    "    return df_train, df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_cloud(points):\n",
    "    pcl = o3d.geometry.PointCloud()\n",
    "    pts = points.reshape(-1, 3)\n",
    "    pcl.points = o3d.utility.Vector3dVector(pts)\n",
    "    o3d.visualization.draw_geometries([pcl])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters of Point CNF: 927513\n",
      "Resume Path:pretrained_models/ae/all/checkpoint.pt\n"
     ]
    }
   ],
   "source": [
    "model = load_model(args)\n",
    "flow = load_flow(args)\n",
    "# le = load_label_encoder(args)\n",
    "df_train, df_test = load_data(args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 2048*5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = ['airplane', 'bag', 'basket', 'bathtub', 'bed', 'bench',\n",
    "       'birdhouse', 'bookshelf', 'bottle', 'bowl', 'bus', 'cabinet',\n",
    "       'camera', 'can', 'cap', 'car', 'cellphone', 'chair', 'clock',\n",
    "       'dishwasher', 'earphone', 'faucet', 'file', 'guitar', 'helmet',\n",
    "       'jar', 'keyboard', 'knife', 'lamp', 'laptop', 'mailbox',\n",
    "       'microphone', 'microwave', 'monitor', 'motorcycle', 'mug', 'piano',\n",
    "       'pillow', 'pistol', 'pot', 'printer', 'remote_control', 'rifle',\n",
    "       'rocket', 'skateboard', 'sofa', 'speaker', 'stove', 'table',\n",
    "       'telephone', 'tin_can', 'tower', 'train', 'vessel', 'washer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mug'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes[35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = 35\n",
    "num_classes = 55\n",
    "\n",
    "context = torch.zeros((1, num_classes))\n",
    "context[0, label] = 1\n",
    "\n",
    "results = model.decode(flow.sample(1, context).squeeze(0), N)\n",
    "\n",
    "visualize_cloud(results[1].cpu().detach().numpy())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
